{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4MScsNpbn95y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import torch.backends.cudnn as cudnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZg4CrWX7npf"
      },
      "source": [
        "### check GPU device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki5jKJyNpQbN",
        "outputId": "fa6297a5-2742-46ae-8dc4-09dc1cc4e48d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Feb 24 21:12:05 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0              24W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPplOCBq7sIf"
      },
      "source": [
        " mount with Goolge Drive if need to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na_sZd5xpQvs",
        "outputId": "4596c279-89dc-4551-d8c8-4701003233e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7iqOJFG8A90"
      },
      "source": [
        "check if cuda is avaiable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sYo73QWpTFz",
        "outputId": "9b76c9f9-3545-45fd-a84e-9899b60c7bc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.1.0+cu121\n",
            "CUDA version: 12.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# check cuda\n",
        "\n",
        "seed = 42\n",
        "CUDA = True and torch.cuda.is_available()\n",
        "print(\"PyTorch version: {}\".format(torch.__version__))\n",
        "if CUDA:\n",
        "    print(\"CUDA version: {}\\n\".format(torch.version.cuda))\n",
        "\n",
        "if CUDA:\n",
        "    torch.cuda.manual_seed(seed)\n",
        "device = torch.device(\"cuda:0\" if CUDA else \"cpu\")\n",
        "cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Kz_NliC8Kc1"
      },
      "source": [
        "to load the MNIST dataset, use the appropriate path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vZejHIL5pYmB"
      },
      "outputs": [],
      "source": [
        "# locate the MNIST data\n",
        "def load_fashion_dataloaders():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Resize(X_DIM),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    train_set = torchvision.datasets.FashionMNIST(\n",
        "        root='/content/drive/MyDrive/Data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_set,\n",
        "        batch_size=8,\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    test_set = torchvision.datasets.FashionMNIST(\n",
        "        root='/content/drive/MyDrive/Data',\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_set,\n",
        "        batch_size=1,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrmO_gNlpfOg",
        "outputId": "c00f1048-0b9f-455e-d3c7-516ed276aff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7500\n",
            "10000\n"
          ]
        }
      ],
      "source": [
        "train_loader, test_loader = load_fashion_dataloaders()\n",
        "print(len(train_loader))\n",
        "print(len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d3-O6KM3pg57"
      },
      "outputs": [],
      "source": [
        "# 10 types of clothes in FashionMNIST dataset\n",
        "def output_label(label):\n",
        "  output_mapping = {\n",
        "      0: \"T-shirt/TOP\",\n",
        "      1: \"Trouser\",\n",
        "      2: \"Pullover\",\n",
        "      3: \"Dress\",\n",
        "      4: \"Coat\",\n",
        "      5: \"Sandal\",\n",
        "      6: \"Shirt\",\n",
        "      7: \"Sneaker\",\n",
        "      8: \"Bag\",\n",
        "      9: \"Ankle Boot\"\n",
        "  }\n",
        "\n",
        "  input = (label.item() if type(label) == torch.Tensor else label)\n",
        "\n",
        "  return output_mapping[input]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "ZSbNYfahrKbd",
        "outputId": "9b5bcbf9-987d-4f63-e5dd-128b3c13eff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "tensor([6, 7, 3, 0, 2, 9, 0, 3])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "img_show, label_show = next(iter(train_loader))\n",
        "print(img_show[0].size())\n",
        "plt.imshow(img_show[0].squeeze(), cmap=\"gray\")\n",
        "print(label_show)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qko7y3D5rR7E"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(CNN, self).__init__()\n",
        "\t\tself.main = nn.Sequential(\n",
        "\n",
        "\t\t\t# input is Z, going into a convolution\n",
        "\t\t\tnn.Conv2d(1, 8, kernel_size=5, stride=1, padding=2),\n",
        "\t\t\tnn.BatchNorm2d(8),\n",
        "\t\t\tnn.ReLU(True),\n",
        "\t\t\tnn.Dropout2d(p=0.1),\n",
        "\n",
        "\t\t\tnn.Conv2d(8, 16, kernel_size=5, stride=2, padding=2),\n",
        "\t\t\tnn.BatchNorm2d(16),\n",
        "\t\t\tnn.ReLU(True),\n",
        "\t\t\tnn.Dropout2d(p=0.1),\n",
        "\n",
        "\t\t\tnn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "\t\t\tnn.BatchNorm2d(32),\n",
        "\t\t\tnn.ReLU(True),\n",
        "\t\t\tnn.Dropout2d(p=0.1),\n",
        "\n",
        "\t\t\tnn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2),\n",
        "\t\t\tnn.BatchNorm2d(64),\n",
        "\t\t\tnn.ReLU(True),\n",
        "\t\t\tnn.Dropout2d(p=0.2),\n",
        "\n",
        "\t\t\tnn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "\t\t\tnn.BatchNorm2d(128),\n",
        "\t\t\tnn.ReLU(True)\n",
        "\t\t)\n",
        "\n",
        "\t\tself.classifier = nn.Sequential(\n",
        "\t\t\tnn.Linear(128, 10),\n",
        "\t\t)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tx = self.main(x) #\n",
        "\t\tx = torch.mean(x.view(x.size(0), x.size(1), -1), dim=2)  # GAP Layer\n",
        "\t\tlogits = self.classifier(x)\n",
        "\t\tpred = F.softmax(logits, dim=1)\n",
        "\n",
        "\t\treturn pred, logits, x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEEU0TAc8gKu"
      },
      "source": [
        "# cnn Model Training on MNIST Fashion Dataset\n",
        "The model was trained for 10 epochs at lr=0.1, 20 epochs more at lr=0.01, 10 epochs more at lr=0.001 and 10 epochs more at lr=0.0002.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoC6WwTSsRno",
        "outputId": "3a2ac7ea-1269-4a01-e60e-d2629f859b64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (main): Sequential(\n",
              "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout2d(p=0.1, inplace=False)\n",
              "    (4): Conv2d(8, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Dropout2d(p=0.1, inplace=False)\n",
              "    (8): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU(inplace=True)\n",
              "    (11): Dropout2d(p=0.1, inplace=False)\n",
              "    (12): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "    (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (14): ReLU(inplace=True)\n",
              "    (15): Dropout2d(p=0.2, inplace=False)\n",
              "    (16): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (18): ReLU(inplace=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = CNN().to(device)\n",
        "model_checkpoint = torch.load('/content/drive/MyDrive/Data/cnn_lr_2e_4_epoch50.pth')\n",
        "model.load_state_dict(model_checkpoint)\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKmXH4tmaA4e"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.00004\n",
        "nn_loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xY3Op8XOszkj",
        "outputId": "a79beb40-23b4-4b7c-a686-68fa0f7ac27d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0/10][0/7500]\tLoss: 1.5862\n",
            "[0/10][500/7500]\tLoss: 1.4612\n",
            "[0/10][1000/7500]\tLoss: 1.4612\n",
            "[0/10][1500/7500]\tLoss: 1.4612\n",
            "[0/10][2000/7500]\tLoss: 1.4614\n",
            "[0/10][2500/7500]\tLoss: 1.4612\n",
            "[0/10][3000/7500]\tLoss: 1.5862\n",
            "[0/10][3500/7500]\tLoss: 1.4612\n",
            "[0/10][4000/7500]\tLoss: 1.4612\n",
            "[0/10][4500/7500]\tLoss: 1.5858\n",
            "[0/10][5000/7500]\tLoss: 1.5862\n",
            "[0/10][5500/7500]\tLoss: 1.5862\n",
            "[0/10][6000/7500]\tLoss: 1.6643\n",
            "[0/10][6500/7500]\tLoss: 1.4612\n",
            "[0/10][7000/7500]\tLoss: 1.4612\n",
            "Epoch: 0\t Average_loss: 1.5523\t Accuracy: 0.9085\n",
            "[1/10][0/7500]\tLoss: 1.5862\n",
            "[1/10][500/7500]\tLoss: 1.4612\n",
            "[1/10][1000/7500]\tLoss: 1.5861\n",
            "[1/10][1500/7500]\tLoss: 1.6985\n",
            "[1/10][2000/7500]\tLoss: 1.4612\n",
            "[1/10][2500/7500]\tLoss: 1.5862\n",
            "[1/10][3000/7500]\tLoss: 1.4612\n",
            "[1/10][3500/7500]\tLoss: 1.6950\n",
            "[1/10][4000/7500]\tLoss: 1.5862\n",
            "[1/10][4500/7500]\tLoss: 1.4612\n",
            "[1/10][5000/7500]\tLoss: 1.4889\n",
            "[1/10][5500/7500]\tLoss: 1.5862\n",
            "[1/10][6000/7500]\tLoss: 1.8308\n",
            "[1/10][6500/7500]\tLoss: 1.7112\n",
            "[1/10][7000/7500]\tLoss: 1.5090\n",
            "Epoch: 1\t Average_loss: 1.5522\t Accuracy: 0.9088\n",
            "[2/10][0/7500]\tLoss: 1.4612\n",
            "[2/10][500/7500]\tLoss: 1.5862\n",
            "[2/10][1000/7500]\tLoss: 1.4612\n",
            "[2/10][1500/7500]\tLoss: 1.4612\n",
            "[2/10][2000/7500]\tLoss: 1.6000\n",
            "[2/10][2500/7500]\tLoss: 1.5862\n",
            "[2/10][3000/7500]\tLoss: 1.4627\n",
            "[2/10][3500/7500]\tLoss: 1.4612\n",
            "[2/10][4000/7500]\tLoss: 1.4612\n",
            "[2/10][4500/7500]\tLoss: 1.4612\n",
            "[2/10][5000/7500]\tLoss: 1.4612\n",
            "[2/10][5500/7500]\tLoss: 1.5862\n",
            "[2/10][6000/7500]\tLoss: 1.4612\n",
            "[2/10][6500/7500]\tLoss: 1.5862\n",
            "[2/10][7000/7500]\tLoss: 1.4612\n",
            "Epoch: 2\t Average_loss: 1.5519\t Accuracy: 0.9089\n",
            "[3/10][0/7500]\tLoss: 1.4612\n",
            "[3/10][500/7500]\tLoss: 1.5862\n",
            "[3/10][1000/7500]\tLoss: 1.4612\n",
            "[3/10][1500/7500]\tLoss: 1.5842\n",
            "[3/10][2000/7500]\tLoss: 1.7112\n",
            "[3/10][2500/7500]\tLoss: 1.4612\n",
            "[3/10][3000/7500]\tLoss: 1.6595\n",
            "[3/10][3500/7500]\tLoss: 1.4612\n",
            "[3/10][4000/7500]\tLoss: 1.7107\n",
            "[3/10][4500/7500]\tLoss: 1.4612\n",
            "[3/10][5000/7500]\tLoss: 1.5839\n",
            "[3/10][5500/7500]\tLoss: 1.4612\n",
            "[3/10][6000/7500]\tLoss: 1.4612\n",
            "[3/10][6500/7500]\tLoss: 1.4612\n",
            "[3/10][7000/7500]\tLoss: 1.5862\n",
            "Epoch: 3\t Average_loss: 1.5530\t Accuracy: 0.9079\n",
            "[4/10][0/7500]\tLoss: 1.4612\n",
            "[4/10][500/7500]\tLoss: 1.4612\n",
            "[4/10][1000/7500]\tLoss: 1.5862\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-186a08833ea8>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-d4c0993fe7a1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# GAP Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;31m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[has-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[has-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# use cumulative moving average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0mexponential_average_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "iters = 0\n",
        "\n",
        "loss_list = []\n",
        "\n",
        "sum_loss = 0.0\n",
        "correct_predictions = 0\n",
        "sum_samples = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  loss_list_epoch = []\n",
        "  sum_loss = 0.0\n",
        "  sum_samples = 0\n",
        "  correct_predictions = 0\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    prediction, _, _ = model(images)\n",
        "    loss = nn_loss(prediction, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    sum_loss += loss.item()\n",
        "    predicted = torch.argmax(prediction, 1)\n",
        "    correct_predictions += (predicted == labels).sum().item()\n",
        "    sum_samples += labels.size(0)\n",
        "\n",
        "    if i % 50 == 0:\n",
        "      loss_list_epoch.append(loss.item())\n",
        "\n",
        "\n",
        "    if (i % 500 == 0):\n",
        "       print('[%d/%d][%d/%d]\\tLoss: %.4f'% (epoch, num_epochs, i, len(train_loader), loss.item()))\n",
        "\n",
        "  average_loss = sum_loss / len(train_loader)\n",
        "  accuracy = correct_predictions / sum_samples\n",
        "  loss_list.append(loss_list_epoch)\n",
        "\n",
        "  print('Epoch: %d\\t Average_loss: %.4f\\t Accuracy: %.4f'% (epoch, average_loss, accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqSUQZkN7dpW"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Data/cnn_lr_4e_3_epoch50.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
